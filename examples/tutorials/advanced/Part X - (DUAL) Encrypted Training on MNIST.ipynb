{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part X - Encrypted Learning\n",
    "\n",
    "https://towardsdatascience.com/handwritten-digit-mnist-pytorch-977b5338e627"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy  # <-- NEW: import the Pysyft library\n",
    "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")  # <-- NEW: define remote worker bob\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")  # <-- NEW: and alice\n",
    "james = sy.VirtualWorker(hook, id=\"james\")  # <-- NEW: and alice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>AutogradTensor>FixedPrecisionTensor>(Wrapper)>[AdditiveSharingTensor]\n",
       "\t-> (Wrapper)>[PointerTensor | me:35537720908 -> bob:44344244096]\n",
       "\t-> (Wrapper)>[PointerTensor | me:20482258853 -> alice:88038887721]\n",
       "\t*crypto provider: james*"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1.]).fix_precision().share(bob, alice, crypto_provider=james, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>AutogradTensor>[PointerTensor | me:94873097749 -> bob:87670374928]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor([1.]).fix_precision().send(bob).share(bob, alice, crypto_provider=james, requires_grad=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutogradTensor>(Wrapper)>FixedPrecisionTensor>(Wrapper)>[AdditiveSharingTensor]\n",
       "\t-> (Wrapper)>[PointerTensor | me:29078829087 -> bob:88158707378]\n",
       "\t-> (Wrapper)>[PointerTensor | me:60224767788 -> alice:21514300422]\n",
       "\t*crypto provider: james*"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 64\n",
    "        self.test_batch_size = 1000\n",
    "        self.epochs = 10\n",
    "        self.lr = 0.02\n",
    "        self.momentum = 0.5\n",
    "        self.no_cuda = False\n",
    "        self.seed = 1\n",
    "        self.log_interval = 30\n",
    "        self.save_model = False\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "    .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.test_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x #F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCRYPTED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, federated_train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(federated_train_loader): # <-- now it is a distributed dataset\n",
    "        if not ENCRYPTED:\n",
    "            model.send(data.location)\n",
    "            target = target.get()\n",
    "            target_onehot = torch.zeros(*target.shape, 10)\n",
    "            target_onehot = target_onehot.scatter(1, target.view(-1, 1), 1)\n",
    "            target = target.send(data.location)\n",
    "            target_onehot = target_onehot.send(data.location)\n",
    "        else:\n",
    "            # Encrypt data TODO remote_get\n",
    "            data = data.get().fix_precision().share(bob, alice, crypto_provider=james, requires_grad=True)\n",
    "            target = target.get()\n",
    "            target_onehot = torch.zeros(*target.shape, 10)\n",
    "            target_onehot = target_onehot.scatter(1, target.view(-1, 1), 1)\n",
    "            target_onehot = target_onehot.fix_precision().share(bob, alice, crypto_provider=james, requires_grad=True)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "        #print(output.shape)\n",
    "        loss = ((output - target_onehot)**2).sum()/output.shape[0]\n",
    "        #print(loss.child.child.child.child.virtual_get())\n",
    "        #loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(time.time() - start_time)\n",
    "        \n",
    "        if not ENCRYPTED:\n",
    "            model.get()\n",
    "        if batch_idx % 5 == 0:\n",
    "            if not ENCRYPTED:\n",
    "                loss = loss.get()# <-- NEW: get the loss back\n",
    "            else:\n",
    "                loss = loss.get().float_precision()\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * args.batch_size, len(federated_train_loader) * args.batch_size,\n",
    "                100. * batch_idx / len(federated_train_loader), loss.item()))\n",
    "        if batch_idx > 9:\n",
    "            return\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test function does not change!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch the training !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008700132369995117\n",
      "Train Epoch: 1 [0/60032 (0%)]\tLoss: 1.152753\n",
      "0.008021116256713867\n",
      "0.008151054382324219\n",
      "0.009250879287719727\n",
      "0.00811910629272461\n",
      "0.008960962295532227\n",
      "Train Epoch: 1 [320/60032 (1%)]\tLoss: 0.850782\n",
      "0.008023977279663086\n",
      "0.009498119354248047\n",
      "0.008041858673095703\n",
      "0.007991790771484375\n",
      "0.008270978927612305\n",
      "Train Epoch: 1 [640/60032 (1%)]\tLoss: 0.780229\n",
      "\n",
      "Test set: Average loss: -0.1972, Accuracy: 5010/10000 (50%)\n",
      "\n",
      "0.0077588558197021484\n",
      "Train Epoch: 2 [0/60032 (0%)]\tLoss: 0.787010\n",
      "0.009422779083251953\n",
      "0.008527040481567383\n",
      "0.009042024612426758\n",
      "0.010618209838867188\n",
      "0.008131027221679688\n",
      "Train Epoch: 2 [320/60032 (1%)]\tLoss: 0.739352\n",
      "0.008008956909179688\n",
      "0.00802302360534668\n",
      "0.00804281234741211\n",
      "0.008756875991821289\n",
      "0.008182048797607422\n",
      "Train Epoch: 2 [640/60032 (1%)]\tLoss: 0.633996\n",
      "\n",
      "Test set: Average loss: -0.2996, Accuracy: 6415/10000 (64%)\n",
      "\n",
      "0.008003711700439453\n",
      "Train Epoch: 3 [0/60032 (0%)]\tLoss: 0.635717\n",
      "0.008285760879516602\n",
      "0.008233785629272461\n",
      "0.008534908294677734\n",
      "0.009061336517333984\n",
      "0.00869131088256836\n",
      "Train Epoch: 3 [320/60032 (1%)]\tLoss: 0.579374\n",
      "0.008514881134033203\n",
      "0.00860285758972168\n",
      "0.008605241775512695\n",
      "0.008798837661743164\n",
      "0.008642911911010742\n",
      "Train Epoch: 3 [640/60032 (1%)]\tLoss: 0.574108\n",
      "\n",
      "Test set: Average loss: -0.3668, Accuracy: 7060/10000 (71%)\n",
      "\n",
      "0.008746862411499023\n",
      "Train Epoch: 4 [0/60032 (0%)]\tLoss: 0.606554\n",
      "0.009335994720458984\n",
      "0.008994102478027344\n",
      "0.009067058563232422\n",
      "0.009556055068969727\n",
      "0.009107828140258789\n",
      "Train Epoch: 4 [320/60032 (1%)]\tLoss: 0.518300\n",
      "0.008974790573120117\n",
      "0.009097099304199219\n",
      "0.06578493118286133\n",
      "0.008978128433227539\n",
      "0.00905299186706543\n",
      "Train Epoch: 4 [640/60032 (1%)]\tLoss: 0.533394\n",
      "\n",
      "Test set: Average loss: -0.4271, Accuracy: 7502/10000 (75%)\n",
      "\n",
      "0.06576299667358398\n",
      "Train Epoch: 5 [0/60032 (0%)]\tLoss: 0.528871\n",
      "0.009296178817749023\n",
      "0.008900880813598633\n",
      "0.009155035018920898\n",
      "0.008718013763427734\n",
      "0.008834123611450195\n",
      "Train Epoch: 5 [320/60032 (1%)]\tLoss: 0.532709\n",
      "0.008744955062866211\n",
      "0.008864164352416992\n",
      "0.009109973907470703\n",
      "0.008707046508789062\n",
      "0.008958101272583008\n",
      "Train Epoch: 5 [640/60032 (1%)]\tLoss: 0.488620\n",
      "\n",
      "Test set: Average loss: -0.4620, Accuracy: 7911/10000 (79%)\n",
      "\n",
      "0.008395910263061523\n",
      "Train Epoch: 6 [0/60032 (0%)]\tLoss: 0.583844\n",
      "0.008868932723999023\n",
      "0.008908987045288086\n",
      "0.008748054504394531\n",
      "0.009817123413085938\n",
      "0.008799076080322266\n",
      "Train Epoch: 6 [320/60032 (1%)]\tLoss: 0.563155\n",
      "0.008831024169921875\n",
      "0.008732795715332031\n",
      "0.008826971054077148\n",
      "0.00941324234008789\n",
      "0.008879899978637695\n",
      "Train Epoch: 6 [640/60032 (1%)]\tLoss: 0.450454\n",
      "\n",
      "Test set: Average loss: -0.4911, Accuracy: 8033/10000 (80%)\n",
      "\n",
      "0.008859872817993164\n",
      "Train Epoch: 7 [0/60032 (0%)]\tLoss: 0.503047\n",
      "0.00909113883972168\n",
      "0.00908207893371582\n",
      "0.008943796157836914\n",
      "0.009505033493041992\n",
      "0.009679794311523438\n",
      "Train Epoch: 7 [320/60032 (1%)]\tLoss: 0.458607\n",
      "0.009256124496459961\n",
      "0.009122848510742188\n",
      "0.009111166000366211\n",
      "0.009205102920532227\n",
      "0.009457111358642578\n",
      "Train Epoch: 7 [640/60032 (1%)]\tLoss: 0.473083\n",
      "\n",
      "Test set: Average loss: -0.5150, Accuracy: 8249/10000 (82%)\n",
      "\n",
      "0.009091854095458984\n",
      "Train Epoch: 8 [0/60032 (0%)]\tLoss: 0.477292\n",
      "0.009576797485351562\n",
      "0.010282039642333984\n",
      "0.010731220245361328\n",
      "0.009762048721313477\n",
      "0.00971221923828125\n",
      "Train Epoch: 8 [320/60032 (1%)]\tLoss: 0.467464\n",
      "0.010373115539550781\n",
      "0.010860919952392578\n",
      "0.011729955673217773\n",
      "0.010323286056518555\n",
      "0.010744094848632812\n",
      "Train Epoch: 8 [640/60032 (1%)]\tLoss: 0.422039\n",
      "\n",
      "Test set: Average loss: -0.5324, Accuracy: 8312/10000 (83%)\n",
      "\n",
      "0.008742809295654297\n",
      "Train Epoch: 9 [0/60032 (0%)]\tLoss: 0.351983\n",
      "0.008942127227783203\n",
      "0.00912785530090332\n",
      "0.009288787841796875\n",
      "0.009809017181396484\n",
      "0.009007930755615234\n",
      "Train Epoch: 9 [320/60032 (1%)]\tLoss: 0.425068\n",
      "0.009318828582763672\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-4e881c4c460a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, device, federated_train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mENCRYPTED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mENCRYPTED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/frameworks/torch/hook/hook.py\u001b[0m in \u001b[0;36mmodule_get_\u001b[0;34m(nn_self)\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0;34m\"\"\"overloads torch.nn instances with get method so that parameters could be sent back to owner\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnn_self\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_self\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPlan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36mget_\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mCalls\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0minplace\u001b[0m \u001b[0moption\u001b[0m \u001b[0mset\u001b[0m \u001b[0mto\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \"\"\"\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mallowed_to_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/frameworks/torch/tensors/interpreters/native.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, inplace, *args, **kwargs)\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;31m#                     return self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;31m# Clean the wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/frameworks/torch/pointers/pointer_tensor.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, deregister_ptr)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mobject\u001b[0m \u001b[0mused\u001b[0m \u001b[0mto\u001b[0m \u001b[0mpoint\u001b[0m \u001b[0mto\u001b[0m \u001b[0;31m#on a remote machine.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \"\"\"\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpointers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectPointer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderegister_ptr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mderegister_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;31m# TODO: remove these 3 lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/frameworks/torch/pointers/object_pointer.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, deregister_ptr)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;31m# get tensor from location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid_at_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;31m# Remove this pointer by default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/workers/base.py\u001b[0m in \u001b[0;36mrequest_obj\u001b[0;34m(self, obj_id, location)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mVariable\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \"\"\"\n\u001b[0;32m--> 519\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSGTYPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOBJ_REQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/workers/base.py\u001b[0m in \u001b[0;36msend_msg\u001b[0;34m(self, msg_type, message, location)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# Step 2: send the message and wait for a response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mbin_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Step 3: deserialize the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/workers/virtual.py\u001b[0m in \u001b[0;36m_send_msg\u001b[0;34m(self, message, location)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mVirtualWorker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseWorker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFederatedClient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBaseWorker\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/workers/virtual.py\u001b[0m in \u001b[0;36m_recv_msg\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/workers/base.py\u001b[0m in \u001b[0;36mrecv_msg\u001b[0;34m(self, bin_message)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;31m# Step 2: Serialize the message to simple python objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mbin_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbin_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/serde/serde.py\u001b[0m in \u001b[0;36mserialize\u001b[0;34m(obj, simplified, force_no_compression, force_no_serialization, force_full_simplification)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_compress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/serde/serde.py\u001b[0m in \u001b[0;36m_compress\u001b[0;34m(decompressed_input_bin)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \"\"\"\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0mcompress_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress_scheme\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_apply_compress_scheme\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecompressed_input_bin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompress_stream\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecompressed_input_bin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcompress_scheme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbyteorder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"big\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcompress_stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/serde/serde.py\u001b[0m in \u001b[0;36m_apply_compress_scheme\u001b[0;34m(decompressed_input_bin)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mdecompressed_input_bin\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mbinary\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mcompressed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \"\"\"\n\u001b[0;32m--> 281\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mapply_lz4_compression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecompressed_input_bin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/PySyft/syft/serde/serde.py\u001b[0m in \u001b[0;36mapply_lz4_compression\u001b[0;34m(decompressed_input_bin)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtuple\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcompressed_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLZ4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \"\"\"\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlz4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecompressed_input_bin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLZ4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Net().to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
    "if ENCRYPTED:\n",
    "    optimizer = optimizer.fix_precision() \n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    if ENCRYPTED:\n",
    "        model = model.fix_precision().share(bob, alice, crypto_provider=james, requires_grad=True)\n",
    "    train(args, model, device, federated_train_loader, optimizer, epoch)\n",
    "    if ENCRYPTED:\n",
    "        model = model.get().float_precision()\n",
    "    test(args, model, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et voil√†! Here you are, you have trained a model on remote data using Federated Learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Last Thing\n",
    "I know there's a question you're dying to ask: **how long does it takes to do Federated Learning compared to normal PyTorch?**\n",
    "\n",
    "The computation time is actually **less than twice the time** used for normal PyTorch execution! More precisely, it takes 1.9 times longer, which is very little compared to the features we were able to add."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "As you observe, we modified 10 lines of code to upgrade the official Pytorch example on MNIST to a real Federated Learning setting!\n",
    "\n",
    "Of course, there are dozen of improvements we could think of. We would like the computation to operate in parallel on the workers and to perform federated averaging, to update the central model every `n` batches only, to reduce the number of messages we use to communicate between workers, etc. These are features we're working on to make Federated Learning ready for a production environment and we'll write about them as soon as they are released!\n",
    "\n",
    "You should now be able to do Federated Learning by yourself! If you enjoyed this and would like to join the movement toward privacy preserving, decentralized ownership of AI and the AI supply chain (data), you can do so in the following ways! \n",
    "\n",
    "### Star PySyft on GitHub\n",
    "\n",
    "The easiest way to help our community is just by starring the repositories! This helps raise awareness of the cool tools we're building.\n",
    "\n",
    "- [Star PySyft](https://github.com/OpenMined/PySyft)\n",
    "\n",
    "### Pick our tutorials on GitHub!\n",
    "\n",
    "We made really nice tutorials to get a better understanding of what Federated and Privacy-Preserving Learning should look like and how we are building the bricks for this to happen.\n",
    "\n",
    "- [Checkout the PySyft tutorials](https://github.com/OpenMined/PySyft/tree/master/examples/tutorials)\n",
    "\n",
    "\n",
    "### Join our Slack!\n",
    "\n",
    "The best way to keep up to date on the latest advancements is to join our community! \n",
    "\n",
    "- [Join slack.openmined.org](http://slack.openmined.org)\n",
    "\n",
    "### Join a Code Project!\n",
    "\n",
    "The best way to contribute to our community is to become a code contributor! If you want to start \"one off\" mini-projects, you can go to PySyft GitHub Issues page and search for issues marked `Good First Issue`.\n",
    "\n",
    "- [Good First Issue Tickets](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)\n",
    "\n",
    "### Donate\n",
    "\n",
    "If you don't have time to contribute to our codebase, but would still like to lend support, you can also become a Backer on our Open Collective. All donations go toward our web hosting and other community expenses such as hackathons and meetups!\n",
    "\n",
    "- [Donate through OpenMined's Open Collective Page](https://opencollective.com/openmined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
