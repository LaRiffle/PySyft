{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part X - Encrypted Learning WITNESS\n",
    "\n",
    "https://towardsdatascience.com/handwritten-digit-mnist-pytorch-977b5338e627"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 64\n",
    "        self.test_batch_size = 1000\n",
    "        self.epochs = 10\n",
    "        self.lr = 0.02\n",
    "        self.momentum = 0.5\n",
    "        self.no_cuda = False\n",
    "        self.seed = 1\n",
    "        self.log_interval = 30\n",
    "        self.save_model = False\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_train_loader = torch.utils.data.DataLoader( # <-- this is now a FederatedDataLoader \n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.test_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x #F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, federated_train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(federated_train_loader): # <-- now it is a distributed dataset\n",
    "        \n",
    "        target_onehot = torch.zeros(*target.shape, 10)\n",
    "        target_onehot = target_onehot.scatter(1, target.view(-1, 1), 1)\n",
    "        \n",
    "        #start_time = time.time()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "        loss = ((output - target_onehot)**2).sum()/output.shape[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #print(time.time() - start_time)\n",
    "\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * args.batch_size, len(federated_train_loader) * args.batch_size,\n",
    "                100. * batch_idx / len(federated_train_loader), loss.item()))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test function does not change!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    first = True\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            if first:\n",
    "                print(model.fc3.weight[:4, :4])\n",
    "                first = False\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch the training !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60032 (0%)]\tLoss: 1.073895\n",
      "Train Epoch: 1 [1920/60032 (3%)]\tLoss: 0.558913\n",
      "Train Epoch: 1 [3840/60032 (6%)]\tLoss: 0.465661\n",
      "Train Epoch: 1 [5760/60032 (10%)]\tLoss: 0.402539\n",
      "Train Epoch: 1 [7680/60032 (13%)]\tLoss: 0.390389\n",
      "Train Epoch: 1 [9600/60032 (16%)]\tLoss: 0.335705\n",
      "Train Epoch: 1 [11520/60032 (19%)]\tLoss: 0.310185\n",
      "Train Epoch: 1 [13440/60032 (22%)]\tLoss: 0.272915\n",
      "Train Epoch: 1 [15360/60032 (26%)]\tLoss: 0.287701\n",
      "Train Epoch: 1 [17280/60032 (29%)]\tLoss: 0.250919\n",
      "Train Epoch: 1 [19200/60032 (32%)]\tLoss: 0.220931\n",
      "Train Epoch: 1 [21120/60032 (35%)]\tLoss: 0.249020\n",
      "Train Epoch: 1 [23040/60032 (38%)]\tLoss: 0.365614\n",
      "Train Epoch: 1 [24960/60032 (42%)]\tLoss: 0.232784\n",
      "Train Epoch: 1 [26880/60032 (45%)]\tLoss: 0.187390\n",
      "Train Epoch: 1 [28800/60032 (48%)]\tLoss: 0.181580\n",
      "Train Epoch: 1 [30720/60032 (51%)]\tLoss: 0.180570\n",
      "Train Epoch: 1 [32640/60032 (54%)]\tLoss: 0.170343\n",
      "Train Epoch: 1 [34560/60032 (58%)]\tLoss: 0.191352\n",
      "Train Epoch: 1 [36480/60032 (61%)]\tLoss: 0.220751\n",
      "Train Epoch: 1 [38400/60032 (64%)]\tLoss: 0.206398\n",
      "Train Epoch: 1 [40320/60032 (67%)]\tLoss: 0.223384\n",
      "Train Epoch: 1 [42240/60032 (70%)]\tLoss: 0.161745\n",
      "Train Epoch: 1 [44160/60032 (74%)]\tLoss: 0.172783\n",
      "Train Epoch: 1 [46080/60032 (77%)]\tLoss: 0.193581\n",
      "Train Epoch: 1 [48000/60032 (80%)]\tLoss: 0.177723\n",
      "Train Epoch: 1 [49920/60032 (83%)]\tLoss: 0.136626\n",
      "Train Epoch: 1 [51840/60032 (86%)]\tLoss: 0.135956\n",
      "Train Epoch: 1 [53760/60032 (90%)]\tLoss: 0.132843\n",
      "Train Epoch: 1 [55680/60032 (93%)]\tLoss: 0.169640\n",
      "Train Epoch: 1 [57600/60032 (96%)]\tLoss: 0.217326\n",
      "Train Epoch: 1 [59520/60032 (99%)]\tLoss: 0.171266\n",
      "         4788713 function calls (4783754 primitive calls) in 14.979 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.087    0.087   14.977   14.977 <ipython-input-10-880310691395>:1(train)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-13-0f37d116c0ec>:12(<module>)\n",
      "        1    0.000    0.000    0.001    0.001 <ipython-input-13-0f37d116c0ec>:4(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-13-0f37d116c0ec>:6(<module>)\n",
      "        1    0.000    0.000   14.977   14.977 <ipython-input-13-0f37d116c0ec>:8(<module>)\n",
      "        1    0.000    0.000    0.001    0.001 <ipython-input-5-22beaa110c32>:2(__init__)\n",
      "      938    0.018    0.000    0.386    0.000 <ipython-input-5-22beaa110c32>:8(forward)\n",
      "   120000    0.118    0.000    0.167    0.000 Image.py:2329(_check_size)\n",
      "    60000    0.191    0.000    0.805    0.000 Image.py:2347(new)\n",
      "    60000    0.229    0.000    1.548    0.000 Image.py:2421(frombuffer)\n",
      "    60000    0.505    0.000    2.082    0.000 Image.py:2482(fromarray)\n",
      "    60000    0.218    0.000    0.325    0.000 Image.py:461(_getencoder)\n",
      "   180000    0.184    0.000    0.184    0.000 Image.py:539(__init__)\n",
      "   180000    0.033    0.000    0.033    0.000 Image.py:559(size)\n",
      "   120000    0.227    0.000    0.365    0.000 Image.py:563(_new)\n",
      "   180000    0.142    0.000    0.220    0.000 Image.py:613(__del__)\n",
      "    60000    0.277    0.000    0.963    0.000 Image.py:725(tobytes)\n",
      "    60000    0.059    0.000    0.088    0.000 Image.py:823(load)\n",
      "    60000    0.035    0.000    0.049    0.000 __init__.py:114(is_tensor)\n",
      "      938    0.006    0.000    0.013    0.000 __init__.py:20(_make_grads)\n",
      "      938    0.006    0.000    0.721    0.001 __init__.py:38(backward)\n",
      "      938    0.001    0.000    0.001    0.000 _collections_abc.py:302(__subclasshook__)\n",
      "    60000    0.025    0.000    0.036    0.000 _util.py:7(isStringType)\n",
      "     1876    0.001    0.000    0.007    0.000 abc.py:137(__instancecheck__)\n",
      "      938    0.000    0.000    0.003    0.000 abc.py:141(__subclasscheck__)\n",
      "        4    0.000    0.000    0.000    0.000 codeop.py:132(__call__)\n",
      " 2814/938    0.017    0.000    0.186    0.000 collate.py:31(default_collate)\n",
      "      938    0.005    0.000    0.163    0.000 collate.py:68(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:192(__iter__)\n",
      "       64    0.000    0.000    0.001    0.000 dataloader.py:195(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:427(__init__)\n",
      "      939    0.071    0.000   13.417    0.014 dataloader.py:557(__next__)\n",
      "      938    0.062    0.000   13.118    0.014 dataloader.py:560(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:675(__del__)\n",
      "     2814    0.009    0.000    0.291    0.000 functional.py:1390(linear)\n",
      "    60000    1.931    0.000    3.780    0.000 functional.py:184(normalize)\n",
      "    60000    0.036    0.000    0.048    0.000 functional.py:23(_is_pil_image)\n",
      "    60000    0.069    0.000    0.138    0.000 functional.py:30(_is_tensor_image)\n",
      "    60000    1.287    0.000    4.948    0.000 functional.py:38(to_tensor)\n",
      "     1876    0.002    0.000    0.029    0.000 functional.py:932(relu)\n",
      "        6    0.000    0.000    0.000    0.000 grad_mode.py:122(__init__)\n",
      "        6    0.000    0.000    0.000    0.000 grad_mode.py:31(__enter__)\n",
      "        6    0.000    0.000    0.000    0.000 grad_mode.py:35(__exit__)\n",
      "        4    0.000    0.000    0.000    0.000 hooks.py:142(__call__)\n",
      "        4    0.000    0.000    0.000    0.000 hooks.py:207(pre_run_code_hook)\n",
      "        3    0.000    0.000    0.000    0.000 init.py:13(_no_grad_uniform_)\n",
      "        6    0.000    0.000    0.000    0.000 init.py:208(_calculate_fan_in_and_fan_out)\n",
      "        3    0.000    0.000    0.000    0.000 init.py:286(_calculate_correct_fan)\n",
      "        3    0.000    0.000    0.001    0.000 init.py:296(kaiming_uniform_)\n",
      "        3    0.000    0.000    0.000    0.000 init.py:33(calculate_gain)\n",
      "        3    0.000    0.000    0.000    0.000 init.py:75(uniform_)\n",
      "        4    0.000    0.000    0.000    0.000 interactiveshell.py:116(<lambda>)\n",
      "        4    0.000    0.000    0.000    0.000 interactiveshell.py:1266(user_global_ns)\n",
      "        4    0.000    0.000   14.979    3.745 interactiveshell.py:3259(run_code)\n",
      "       96    0.000    0.000    0.005    0.000 iostream.py:195(schedule)\n",
      "       64    0.000    0.000    0.000    0.000 iostream.py:307(_is_master_process)\n",
      "       64    0.000    0.000    0.001    0.000 iostream.py:320(_schedule_flush)\n",
      "       64    0.000    0.000    0.005    0.000 iostream.py:382(write)\n",
      "       96    0.000    0.000    0.000    0.000 iostream.py:93(_event_pipe)\n",
      "        4    0.000    0.000    0.000    0.000 ipstruct.py:125(__getattr__)\n",
      "        3    0.000    0.000    0.001    0.000 linear.py:72(__init__)\n",
      "        3    0.000    0.000    0.001    0.000 linear.py:83(reset_parameters)\n",
      "     2814    0.010    0.000    0.305    0.000 linear.py:90(forward)\n",
      "       65    0.000    0.000    0.000    0.000 mnist.py:102(__len__)\n",
      "    60000    1.258    0.000   13.056    0.000 mnist.py:80(__getitem__)\n",
      "        6    0.000    0.000    0.000    0.000 module.py:128(register_parameter)\n",
      "      4/1    0.000    0.000    0.000    0.000 module.py:191(_apply)\n",
      "        1    0.000    0.000    0.000    0.000 module.py:310(to)\n",
      "        6    0.000    0.000    0.000    0.000 module.py:383(convert)\n",
      " 3752/938    0.021    0.000    0.395    0.000 module.py:487(__call__)\n",
      "     8460    0.009    0.000    0.009    0.000 module.py:525(__getattr__)\n",
      "       59    0.000    0.000    0.000    0.000 module.py:541(__setattr__)\n",
      "        9    0.000    0.000    0.000    0.000 module.py:542(remove_from)\n",
      "        4    0.000    0.000    0.000    0.000 module.py:65(__init__)\n",
      "        7    0.000    0.000    0.000    0.000 module.py:780(_named_members)\n",
      "        7    0.000    0.000    0.000    0.000 module.py:793(parameters)\n",
      "        7    0.000    0.000    0.000    0.000 module.py:817(named_parameters)\n",
      "        4    0.000    0.000    0.000    0.000 module.py:838(<lambda>)\n",
      "       14    0.000    0.000    0.000    0.000 module.py:891(children)\n",
      "       14    0.000    0.000    0.000    0.000 module.py:900(named_children)\n",
      "     11/5    0.000    0.000    0.000    0.000 module.py:947(named_modules)\n",
      "      4/1    0.000    0.000    0.000    0.000 module.py:985(train)\n",
      "      938    0.013    0.000    0.153    0.000 optimizer.py:158(zero_grad)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:175(add_param_group)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:32(__init__)\n",
      "        6    0.000    0.000    0.000    0.000 parameter.py:23(__new__)\n",
      "      939    0.027    0.000    0.042    0.000 sampler.py:170(__iter__)\n",
      "       64    0.000    0.000    0.001    0.000 sampler.py:180(__len__)\n",
      "       64    0.000    0.000    0.000    0.000 sampler.py:68(num_samples)\n",
      "        1    0.000    0.000    0.002    0.002 sampler.py:75(__iter__)\n",
      "       64    0.000    0.000    0.000    0.000 sampler.py:81(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 sgd.py:51(__init__)\n",
      "      938    0.036    0.000    0.144    0.000 sgd.py:71(step)\n",
      "       96    0.004    0.000    0.004    0.000 socket.py:337(send)\n",
      "       65    0.000    0.000    0.000    0.000 tensor.py:417(__len__)\n",
      "       18    0.000    0.000    0.000    0.000 tensor.py:438(__hash__)\n",
      "      938    0.005    0.000    0.726    0.001 tensor.py:79(backward)\n",
      "       96    0.000    0.000    0.000    0.000 threading.py:1038(_wait_for_tstate_lock)\n",
      "       96    0.000    0.000    0.000    0.000 threading.py:1080(is_alive)\n",
      "       96    0.000    0.000    0.000    0.000 threading.py:507(is_set)\n",
      "    60000    0.221    0.000    4.002    0.000 transforms.py:156(__call__)\n",
      "    60000    0.209    0.000    9.439    0.000 transforms.py:59(__call__)\n",
      "    60000    0.280    0.000    5.228    0.000 transforms.py:84(__call__)\n",
      "    60000    0.168    0.000    0.168    0.000 {built-in method PIL._imaging.fill}\n",
      "    60000    0.189    0.000    0.189    0.000 {built-in method PIL._imaging.map_buffer}\n",
      "    60000    0.042    0.000    0.042    0.000 {built-in method PIL._imaging.raw_encoder}\n",
      "     1876    0.003    0.000    0.006    0.000 {built-in method _abc._abc_instancecheck}\n",
      "      938    0.002    0.000    0.003    0.000 {built-in method _abc._abc_subclasscheck}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method _make_subclass}\n",
      "     2814    0.262    0.000    0.262    0.000 {built-in method addmm}\n",
      "   120000    0.715    0.000    0.715    0.000 {built-in method as_tensor}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.compile}\n",
      "        4    0.000    0.000   14.978    3.745 {built-in method builtins.exec}\n",
      "    60000    0.051    0.000    0.051    0.000 {built-in method builtins.getattr}\n",
      "   360944    0.078    0.000    0.078    0.000 {built-in method builtins.hasattr}\n",
      "       18    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
      "   492402    0.162    0.000    0.169    0.000 {built-in method builtins.isinstance}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425014/424757    0.068    0.000    0.069    0.000 {built-in method builtins.len}\n",
      "    60000    0.048    0.000    0.048    0.000 {built-in method builtins.max}\n",
      "      939    0.001    0.000    0.043    0.000 {built-in method builtins.next}\n",
      "       32    0.000    0.000    0.006    0.000 {built-in method builtins.print}\n",
      "    60000    0.117    0.000    0.117    0.000 {built-in method from_buffer}\n",
      "       15    0.000    0.000    0.000    0.000 {built-in method math.sqrt}\n",
      "      938    0.006    0.000    0.006    0.000 {built-in method ones_like}\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        1    0.001    0.001    0.001    0.001 {built-in method randperm}\n",
      "     1876    0.027    0.000    0.027    0.000 {built-in method relu}\n",
      "      938    0.143    0.000    0.143    0.000 {built-in method stack}\n",
      "      938    0.010    0.000    0.010    0.000 {built-in method tensor}\n",
      "     3752    0.005    0.000    0.005    0.000 {built-in method torch._C._get_tracing_state}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._nn._parse_to}\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method torch._C.is_grad_enabled}\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method torch._C.set_grad_enabled}\n",
      "      938    0.008    0.000    0.008    0.000 {built-in method zeros}\n",
      "       96    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "       16    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "     5628    0.109    0.000    0.109    0.000 {method 'add_' of 'torch._C._TensorBase' objects}\n",
      "       96    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "   120939    0.020    0.000    0.020    0.000 {method 'append' of 'list' objects}\n",
      "    60000    0.405    0.000    0.405    0.000 {method 'clone' of 'torch._C._TensorBase' objects}\n",
      "    60000    0.017    0.000    0.017    0.000 {method 'contiguous' of 'torch._C._TensorBase' objects}\n",
      "   120000    0.028    0.000    0.028    0.000 {method 'copy' of 'dict' objects}\n",
      "     5622    0.005    0.000    0.005    0.000 {method 'detach_' of 'torch._C._TensorBase' objects}\n",
      "     2885    0.001    0.000    0.001    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "    60000    1.137    0.000    1.137    0.000 {method 'div' of 'torch._C._TensorBase' objects}\n",
      "    60000    0.259    0.000    0.259    0.000 {method 'div_' of 'torch._C._TensorBase' objects}\n",
      "    60000    0.144    0.000    0.144    0.000 {method 'encode' of 'ImagingEncoder' objects}\n",
      "    60000    0.462    0.000    0.462    0.000 {method 'float' of 'torch._C._TensorBase' objects}\n",
      "       38    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "    60162    0.013    0.000    0.013    0.000 {method 'get' of 'dict' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method 'is_floating_point' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'isdisjoint' of 'set' objects}\n",
      "       33    0.000    0.000    0.000    0.000 {method 'item' of 'torch._C._TensorBase' objects}\n",
      "       20    0.000    0.000    0.000    0.000 {method 'items' of 'collections.OrderedDict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "    60000    0.012    0.000    0.012    0.000 {method 'join' of 'bytes' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\n",
      "    60000    0.019    0.000    0.019    0.000 {method 'ndimension' of 'torch._C._TensorBase' objects}\n",
      "      938    0.001    0.000    0.001    0.000 {method 'numel' of 'torch._C._TensorBase' objects}\n",
      "    60000    0.180    0.000    0.180    0.000 {method 'numpy' of 'torch._C._TensorBase' objects}\n",
      "    60000    0.029    0.000    0.029    0.000 {method 'pixel_access' of 'ImagingCore' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'random_' of 'torch._C._TensorBase' objects}\n",
      "      938    0.701    0.001    0.701    0.001 {method 'run_backward' of 'torch._C._EngineBase' objects}\n",
      "      938    0.019    0.000    0.019    0.000 {method 'scatter' of 'torch._C._TensorBase' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}\n",
      "    60000    0.035    0.000    0.035    0.000 {method 'setimage' of 'ImagingEncoder' objects}\n",
      "       12    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C._TensorBase' objects}\n",
      "    60000    0.333    0.000    0.333    0.000 {method 'sub_' of 'torch._C._TensorBase' objects}\n",
      "      938    0.012    0.000    0.012    0.000 {method 'sum' of 'torch._C._TensorBase' objects}\n",
      "     2814    0.020    0.000    0.020    0.000 {method 't' of 'torch._C._TensorBase' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method 'to' of 'torch._C._TensorBase' objects}\n",
      "        1    0.001    0.001    0.001    0.001 {method 'tolist' of 'torch._C._TensorBase' objects}\n",
      "   120000    0.417    0.000    0.417    0.000 {method 'transpose' of 'torch._C._TensorBase' objects}\n",
      "        6    0.001    0.000    0.001    0.000 {method 'uniform_' of 'torch._C._TensorBase' objects}\n",
      "     7508    0.002    0.000    0.002    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
      "    61876    0.409    0.000    0.409    0.000 {method 'view' of 'torch._C._TensorBase' objects}\n",
      "     5622    0.135    0.000    0.135    0.000 {method 'zero_' of 'torch._C._TensorBase' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cp = cProfile.Profile()\n",
    "cp.enable()\n",
    "\n",
    "model = Net().to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
    "\n",
    "for epoch in range(1, 2):#args.epochs + 1\n",
    "    train(args, model, device, federated_train_loader, optimizer, epoch)\n",
    "    #test(args, model, device, test_loader)\n",
    "    \n",
    "cp.disable()\n",
    "cp.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et voil√†! Here you are, you have trained a model on remote data using Federated Learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Last Thing\n",
    "I know there's a question you're dying to ask: **how long does it takes to do Federated Learning compared to normal PyTorch?**\n",
    "\n",
    "The computation time is actually **less than twice the time** used for normal PyTorch execution! More precisely, it takes 1.9 times longer, which is very little compared to the features we were able to add."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "As you observe, we modified 10 lines of code to upgrade the official Pytorch example on MNIST to a real Federated Learning setting!\n",
    "\n",
    "Of course, there are dozen of improvements we could think of. We would like the computation to operate in parallel on the workers and to perform federated averaging, to update the central model every `n` batches only, to reduce the number of messages we use to communicate between workers, etc. These are features we're working on to make Federated Learning ready for a production environment and we'll write about them as soon as they are released!\n",
    "\n",
    "You should now be able to do Federated Learning by yourself! If you enjoyed this and would like to join the movement toward privacy preserving, decentralized ownership of AI and the AI supply chain (data), you can do so in the following ways! \n",
    "\n",
    "### Star PySyft on GitHub\n",
    "\n",
    "The easiest way to help our community is just by starring the repositories! This helps raise awareness of the cool tools we're building.\n",
    "\n",
    "- [Star PySyft](https://github.com/OpenMined/PySyft)\n",
    "\n",
    "### Pick our tutorials on GitHub!\n",
    "\n",
    "We made really nice tutorials to get a better understanding of what Federated and Privacy-Preserving Learning should look like and how we are building the bricks for this to happen.\n",
    "\n",
    "- [Checkout the PySyft tutorials](https://github.com/OpenMined/PySyft/tree/master/examples/tutorials)\n",
    "\n",
    "\n",
    "### Join our Slack!\n",
    "\n",
    "The best way to keep up to date on the latest advancements is to join our community! \n",
    "\n",
    "- [Join slack.openmined.org](http://slack.openmined.org)\n",
    "\n",
    "### Join a Code Project!\n",
    "\n",
    "The best way to contribute to our community is to become a code contributor! If you want to start \"one off\" mini-projects, you can go to PySyft GitHub Issues page and search for issues marked `Good First Issue`.\n",
    "\n",
    "- [Good First Issue Tickets](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)\n",
    "\n",
    "### Donate\n",
    "\n",
    "If you don't have time to contribute to our codebase, but would still like to lend support, you can also become a Backer on our Open Collective. All donations go toward our web hosting and other community expenses such as hackathons and meetups!\n",
    "\n",
    "- [Donate through OpenMined's Open Collective Page](https://opencollective.com/openmined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
