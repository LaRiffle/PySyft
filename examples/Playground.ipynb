{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Torch was already hooked... skipping hooking process\n"
     ]
    }
   ],
   "source": [
    "import syft as sy\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import torch.autograd as autograd\n",
    "\n",
    "syft = sy \n",
    "\n",
    "hook = sy.TorchHook(th)\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
    "charlie = sy.VirtualWorker(hook, id=\"charlie\")\n",
    "james = sy.VirtualWorker(hook, id=\"james\")\n",
    "crypto_provider = james\n",
    "torch = th\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ea0775aef591>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a.get().grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = Variable(torch.ones(a.shape))\n",
    "ones = ones.send(a.location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.backward(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.tensor([0.,0], requires_grad=True).send(bob)\n",
    "y = th.tensor([0.,0]).send(bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.backward(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "from syft import TorchHook\n",
    "hook = TorchHook(th)\n",
    "th.tensor([0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice._objects[82398314832]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([1.23567])\n",
    "t.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me = hook.local_worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_sh = t.fix_precision().share(alice, bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sh = t_sh * t_sh\n",
    "r_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r_sh.get().float_precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mul(t_sh, r_sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor(range(-10, 10))*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_prec_tolerance_by_method = {\n",
    "    \"maclaurin\": {3: 7 / 100, 4: 15 / 100, 5: 15 / 100}\n",
    "}\n",
    "\n",
    "for method, fix_prec_tolerance in fix_prec_tolerance_by_method.items():\n",
    "    print(method)\n",
    "    for prec_frac, tolerance in fix_prec_tolerance.items():\n",
    "        print(prec_frac)\n",
    "        t = torch.tensor(range(-10, 10)) * 0.5\n",
    "        t_sh = t.fix_precision(precision_fractional=prec_frac).share(\n",
    "            alice, bob, crypto_provider=james\n",
    "        )\n",
    "        r_sh = t_sh.sigmoid(method=method)\n",
    "        r = r_sh.get().float_prec()\n",
    "        t = t.sigmoid()\n",
    "        diff = (r - t).abs().max()\n",
    "        norm = (r + t).abs().max() / 2\n",
    "\n",
    "        assert (diff / (tolerance * norm)) < 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([                2,                 191, 1,\n",
    "                          0])\n",
    "t = t.fix_prec().child\n",
    "t[1: 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor(range(-10, 10))*0.5\n",
    "t.sigmoid()\n",
    "t_sh = t.fix_prec(precision_fractional=5)\n",
    "r1 = t_sh.sigmoid().float_prec()\n",
    "one = t_sh * 0 + 1\n",
    "r2 = (one / (1 + (t_sh * -1).exp())).float_prec()\n",
    "print(t.sigmoid())\n",
    "print(r1)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor(3)\n",
    "print(t.fix_prec(precision_fractional=5).exp().float_prec())\n",
    "t = torch.tensor(-3)\n",
    "t1 = t.fix_prec(precision_fractional=5)\n",
    "(t1 * -1).exp().float_prec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.tensor([[1, 0.2], [0.4, 4.0]])\n",
    "m @ m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.tensor([[1, 0.2], [0.4, 4.0]])\n",
    "m ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse(self, iterations=10):\n",
    "    \"\"\"\n",
    "    Computes an approximation of the matrix inversion using Newton-Schulz\n",
    "    iterations\n",
    "    \"\"\"\n",
    "    assert len(self.shape) >= 2, \"Can't compute inverse on non-matrix\"\n",
    "    assert self.shape[-1] == self.shape[-2], \"Must be batches of square matrices\"\n",
    "\n",
    "    #inverse = 3 * (0.5 - self).exp() + 0.003\n",
    "    inverse = (0.1 * torch.eye(self.shape[-1]))\n",
    "\n",
    "    print(inverse)\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        inverse = 2 * inverse - inverse @ self @ inverse\n",
    "        print(inverse)\n",
    "\n",
    "    return inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.tensor([[1, 0.2], [0.4, 4.0]])\n",
    "m.inverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse(m.fix_prec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = m.fix_prec()\n",
    "x.inverse().float_prec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.tensor([[1, 2], [3, 4.0]])\n",
    "x = m.fix_prec()\n",
    "y = torch.matmul(x, x).float_prec()\n",
    "\n",
    "assert (y == torch.matmul(m, m)).all()\n",
    "\n",
    "# with AST\n",
    "m = torch.tensor([[1, 2], [3, 4.0]])\n",
    "x = m.fix_prec()\n",
    "y = m.fix_prec().share(bob, alice, crypto_provider=james)\n",
    "\n",
    "z = (x @ y).get().float_prec()\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice.clear_objects()\n",
    "bob.clear_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.tensor([2., 2., 2.])\n",
    "p = x.send(bob).send(alice)\n",
    "\n",
    "z = p + p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@sy.func2plan([th.Size((3,))])\n",
    "def plan_double_abs(x):\n",
    "    x = x.send(bob)\n",
    "    x = x + x\n",
    "    x = th.abs(x)\n",
    "    return x\n",
    "\n",
    "ptr_result = plan_double_abs(th.ones(3))\n",
    "assert isinstance(ptr_result.child, sy.PointerTensor)\n",
    "result = ptr_result.get()\n",
    "print(result)\n",
    "assert torch.equal(result, th.tensor([2., 2., 2.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_hospital = bob\n",
    "small_hospital, crypto_provider = alice, james"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = nn.Parameter(torch.tensor([[0], [0], [1], [1.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.data = torch.tensor([[0], [0], [1], [1.0]]) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Toy Model\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc = torch.nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def federated():\n",
    "    # A Toy Dataset\n",
    "    data = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1.0]])\n",
    "    target = torch.tensor([[0], [0], [1], [1.0]])\n",
    "\n",
    "    model = Net()\n",
    "\n",
    "    model_weight = model.fc.weight.copy()\n",
    "\n",
    "    # Training Logic\n",
    "    opt = torch.optim.SGD(params=model.parameters(), lr=0.1)\n",
    "\n",
    "    data = data.send(big_hospital)\n",
    "    target = target.send(big_hospital)\n",
    "\n",
    "    # NEW) send model to correct worker\n",
    "    model.send(data.location)\n",
    "\n",
    "    # 1) erase previous gradients (if they exist)\n",
    "    opt.zero_grad()\n",
    "\n",
    "    # 2) make a prediction\n",
    "    pred = model(data)\n",
    "\n",
    "    # 3) calculate how much we missed\n",
    "    loss = ((pred - target) ** 2).sum()\n",
    "\n",
    "    # 4) figure out which weights caused us to miss\n",
    "    loss.backward()\n",
    "\n",
    "    # 5) change those weights\n",
    "    opt.step()\n",
    "\n",
    "    assert (model_weight - model.get().fc.weight).sum().abs() > 1.0e-3\n",
    "    \n",
    "federated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.nn.Parameter(th.tensor([1., 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.data = th.tensor([1., 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.Rdata = x.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.Rdata = th.tensor([1., 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.nn.Parameter.Zdata = th.nn.Parameter.data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.Zdata = th.tensor([1., 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(th.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(th.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = x.send(bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob._known_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse(self, iterations=20, alpha=1):\n",
    "    \"\"\"\n",
    "    Computes an approximation of the matrix inversion using Newton-Schulz\n",
    "    iterations  \n",
    "    Source NASA: https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/19920002505.pdf\n",
    "    \"\"\"\n",
    "    assert len(self.shape) >= 2, \"Can't compute inverse on non-matrix\"\n",
    "    assert self.shape[-1] == self.shape[-2], \"Must be batches of square matrices\"\n",
    "    \n",
    "    eye = torch.eye(self.shape[-1])\n",
    "    inverse = alpha * self.t()\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        inverse = inverse @ (2 * eye - self @ inverse)\n",
    "        #print(inverse)\n",
    "\n",
    "    return inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "for alpha in [0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02]:\n",
    "    success = 0\n",
    "    for i in range(n):\n",
    "        m = th.empty(4, 4).random_(-1000, 1000)/100\n",
    "        d = (m.inverse() - inverse(m)).abs().sum()\n",
    "        if d < 0.5:\n",
    "            success += 1\n",
    "        else:\n",
    "            pass\n",
    "            #print('=====', i)\n",
    "            #print(m.inverse())\n",
    "            #print(inverse(m))\n",
    "\n",
    "    print(f\"{alpha}\\t\", '='*int(success), 'o'*int(n-success), int(success/n*100), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.empty(4, 4).random_(0, 10).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = th.tensor([[1., 2], [3, 4]])\n",
    "m.inverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = m.fix_prec(precision_fractional=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.inverse().float_prec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.inverse() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m ** -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = th.tensor([[1., 2], [3, 4]])\n",
    "iterations = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 + m / 2 ** iterations).matrix_power(2 ** iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.matrix_power(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.inverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = m.fix_prec(precision_fractional=5).share(alice, bob, crypto_provider=james)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.inverse().get().float_prec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor([1.])\n",
    "t2 = torch.tensor([5.])\n",
    "x1 = t1.fix_prec().share(bob, alice, crypto_provider=james)\n",
    "x2 = t2.fix_prec().share(bob, alice, crypto_provider=james)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = 1.\n",
    "t2 = torch.tensor([5.])\n",
    "x1 = t1\n",
    "x2 = t2.fix_prec().share(bob, alice, crypto_provider=james)\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (x1 / x2).get().float_prec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 / t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.__div__(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.__rdiv__(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = #\n",
    "t2 = torch.tensor([5.])\n",
    "t1 / t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y = (x1 / x2).get().float_prec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.tensor([4., 6, 8])\n",
    "x = x.fix_prec(precision_fractional=3).share(alice, bob, crypto_provider=james)\n",
    "\n",
    "q = th.tensor([2.])\n",
    "q = q.fix_prec(precision_fractional=3).share(alice, bob, crypto_provider=james)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = x / q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.get().float_prec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Size([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.tensor([-1.])\n",
    "x = x.fix_prec(precision_fractional=3).share(alice, bob)\n",
    "\n",
    "y = (x / 2)\n",
    "print(y)\n",
    "print(y.get().float_prec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "content = 'content \"\"\"hod  '+ \"\"\"s \n",
    "\"\"\" +\"\"\"s def hjleh()\n",
    "\"\"\" + 'le\"\"\"' \n",
    "#content = content.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = re.search(\"def (\\w+?)\\(\", content)\n",
    "if results is not None:\n",
    "    script_name = results.group(1)\n",
    "else:\n",
    "    script_name = f\"{script_file} (looks broken)\"\n",
    "script_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = re.search('\"\"\"(.*?)\"\"\"', content)\n",
    "if results is not None:\n",
    "    script_name = results.group(1)\n",
    "else:\n",
    "    script_name = f\"sss (looks broken)\"\n",
    "print(script_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@sy.func2plan(args_shape=[(1,)])\n",
    "def my_plan(data):\n",
    "    x = data * 2\n",
    "    y = (x - 2) * 10\n",
    "    return x + y\n",
    "\n",
    "x = th.tensor([-1, 2, 3])\n",
    "local_res = my_plan(x)\n",
    "\n",
    "plan_ptr = my_plan.send(alice)\n",
    "x_ptr = x.send(alice)\n",
    "p = plan_ptr(x_ptr)\n",
    "print(p)\n",
    "plan_res = p.get()\n",
    "\n",
    "assert (plan_res == local_res).all()\n",
    "\n",
    "# delete remote object before websocket connection termination\n",
    "del x_ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(sy.Plan):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 3)\n",
    "        self.fc2 = nn.Linear(3, 2)\n",
    "\n",
    "        self.bias = th.tensor([1000.0])\n",
    "\n",
    "        self.state += [\"fc1\", \"fc2\", \"bias\"]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=0) + self.bias\n",
    "\n",
    "net = Net()\n",
    "\n",
    "x = th.tensor([-1, 2.0])\n",
    "local_res = net(x)\n",
    "assert not net.is_built\n",
    "\n",
    "net.build(x)\n",
    "\n",
    "plan_ptr = net.send(alice)\n",
    "x_ptr = x.send(alice)\n",
    "remote_res = plan_ptr(x_ptr).get()\n",
    "\n",
    "assert (remote_res == local_res).all()\n",
    "\n",
    "# delete remote object before websocket connection termination\n",
    "del x_ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x11 = th.tensor([-1, 2.0]).tag(\"input_data\")\n",
    "x21 = th.tensor([-1, 2.0]).tag(\"input_data\")\n",
    "\n",
    "device_1 = sy.VirtualWorker(hook, id=\"device_1\", data=(x11,))\n",
    "device_2 = sy.VirtualWorker(hook, id=\"device_2\", data=(x21,))\n",
    "\n",
    "class Net(sy.Plan):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 3)\n",
    "        self.fc2 = nn.Linear(3, 1)\n",
    "\n",
    "        self.bias = th.tensor([1000.0])\n",
    "\n",
    "        self.state += [\"fc1\", \"fc2\", \"bias\"]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=0) + self.bias\n",
    "\n",
    "net = Net()\n",
    "\n",
    "# build\n",
    "net.build(th.tensor([1, 2.0]))\n",
    "\n",
    "net.send(device_1)\n",
    "pointer_to_data = x11.send(device_1)#device_1.search(\"input_data\")[0]\n",
    "pointer_to_result = net(pointer_to_data)\n",
    "pointer_to_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([5])\n",
    "x_bin = decompose(x)[0]\n",
    "print(x_bin)\n",
    "moduli = 2 ** torch.arange(Q_BITS)\n",
    "print(moduli)\n",
    "coeffs = (torch.exp(x_bin.float()) ** moduli.float())\n",
    "print(torch.prod(coeffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.7183 * 54.5981"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = torch.exp(torch.tensor(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e**5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " e**(1*2**2 + 0*2**1 + 1*2**0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(e**1)**(2**2) * (e**0)**(2**1) * (e**1)**(2**0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(e**(2**2) if 1 else 1)*(e**(2**1) if 0 else 1)*(e**(2**0) if 1 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e**5 == (e**(2**2) if 1 else 1)*(e**(2**1) if 0 else 1)*(e**(2**0) if 1 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_bit(x):\n",
    "    # Take a bit (0 or 1, here 0 for example)and share it in a *binary* field\n",
    "    #x = torch.tensor([0])\n",
    "    x_sh = x.share(alice, bob, crypto_provider=crypto_provider, field=2)\n",
    "    \n",
    "    # Access shares\n",
    "    x0, x1 = x_sh.child.child['alice'], x_sh.child.child['bob']\n",
    "    x0 = x0.float()\n",
    "    x1 = x1.float()\n",
    "    print(alice._objects[x0.id_at_location], bob._objects[x1.id_at_location])\n",
    "    \n",
    "    # Compute privately the wrap field bit, which decrypts to 1 iff x0+x1 >= 2  \n",
    "    x0_sh = x0.fix_precision().share(alice, bob, crypto_provider=charlie).get()\n",
    "    x1_sh = x1.fix_precision().share(alice, bob, crypto_provider=charlie).get()\n",
    "    wrap_field = x0_sh * x1_sh \n",
    "    \n",
    "    # Compute exp of shares\n",
    "    exp_x0, exp_x1 = [torch.exp(x0), torch.exp(x1)]\n",
    "    alice._objects[exp_x0.id_at_location], bob._objects[exp_x1.id_at_location]\n",
    "\n",
    "    # Share the exp of shares\n",
    "    exp_x0_sh = exp_x0.fix_precision().share(alice, bob, crypto_provider=charlie).get()\n",
    "    exp_x1_sh = exp_x1.fix_precision().share(alice, bob, crypto_provider=charlie).get()\n",
    "\n",
    "    # Apply exp(x0 + x1) =  exp(x0) *  exp(x1) formula + a wrapping correction if needed\n",
    "    one = torch.tensor([1.]).fix_precision()\n",
    "    inv_exp_field_size = torch.exp(-torch.tensor([2.])).fix_precision()\n",
    "    exp_sh = exp_x0_sh * exp_x1_sh * (wrap_field * (inv_exp_field_size - one) + one)\n",
    "\n",
    "    # Open and get 1.0\n",
    "    return exp_sh\n",
    "\n",
    "\n",
    "# Example\n",
    "x = torch.tensor([0, 1, 0, 1, 0, 1, 1, 0, 0])\n",
    "exp_x = exp_bit(x)\n",
    "print(exp_x.get().float_prec())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear text demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([5, 3, 1])\n",
    "x_bin = decompose(x)\n",
    "\n",
    "exp_x_bin = torch.exp(x_bin.float())\n",
    "print(exp_x_bin)\n",
    "exp_x_bin_list = exp_x_bin.unbind(dim=1)\n",
    "print(exp_x_bin_list)\n",
    "\n",
    "moduli = 2 ** torch.arange(Q_BITS)\n",
    "moduli_list = map(lambda x:x.item(), moduli.unbind(dim=0))\n",
    "\n",
    "coeffs_list = [\n",
    "    xp_x_bin_item ** modulo\n",
    "    for xp_x_bin_item, modulo\n",
    "    in zip(exp_x_bin_list, moduli_list)\n",
    "]\n",
    "\n",
    "coeffs = torch.stack(coeffs_list).t()\n",
    "print(coeffs)\n",
    "\n",
    "torch.prod(coeffs, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encrypted Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([5, 3, 1])\n",
    "x_bin = decompose(x)\n",
    "print('bin', x_bin)\n",
    "exp_x_bin_sh = exp_bit(x_bin)\n",
    "print('exp sh', exp_x_bin_sh.child.child.virtual_get())\n",
    "exp_x_bin_list = torch.unbind(exp_x_bin_sh, dim=1)\n",
    "\n",
    "moduli = 2 ** torch.arange(Q_BITS)\n",
    "moduli_list = list(map(lambda x:x.fix_precision(precision_fractional=0), moduli.unbind(dim=0)))\n",
    "\n",
    "coeffs_list = [\n",
    "    xp_x_bin_item ** modulo\n",
    "    for xp_x_bin_item, modulo\n",
    "    in zip(exp_x_bin_list, moduli_list)\n",
    "]\n",
    "\n",
    "exp_x_sh = coeffs_list[0]\n",
    "for coeff in coeffs_list[1:]:\n",
    "    exp_x_sh = exp_x_sh * coeff\n",
    "\n",
    "#coeffs = torch.stack(coeffs_list).t()\n",
    "#print('coeffs', coeffs.child.child.virtual_get())\n",
    "\n",
    "#exp_x_sh = torch.prod(coeffs, dim=1)\n",
    "\n",
    "print('exp_x', exp_x_sh.get().float_prec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([5, 3]).fix_precision()\n",
    "\n",
    "torch.prod(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.tensor([5, 3])\n",
    "x_bin = decompose(x)\n",
    "\n",
    "exp_x_bin = torch.exp(x_bin.float())\n",
    "print(exp_x_bin)\n",
    "exp_x_bin_list = exp_x_bin.unbind(dim=1)\n",
    "print(exp_x_bin_list)\n",
    "\n",
    "moduli = 2 ** torch.arange(Q_BITS)\n",
    "moduli_list = map(lambda x:x.item(), moduli.unbind(dim=0))\n",
    "\n",
    "coeffs_list = [\n",
    "    xp_x_bin_item ** modulo\n",
    "    for xp_x_bin_item, modulo\n",
    "    in zip(exp_x_bin_list, moduli_list)\n",
    "]\n",
    "\n",
    "coeffs = torch.stack(coeffs_list).t()\n",
    "print(coeffs)\n",
    "\n",
    "torch.prod(coeffs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a bit (0 or 1, here 0 for example)and share it in a *binary* field\n",
    "x = torch.tensor([0])\n",
    "x_sh = x.share(alice, bob, crypto_provider=crypto_provider, field=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access shares\n",
    "x0, x1 = x_sh.child.child['alice'], x_sh.child.child['bob']\n",
    "x0 = x0.float()\n",
    "x1 = x1.float()\n",
    "print(alice._objects[x0.id_at_location], bob._objects[x1.id_at_location])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute privately the wrap field bit, which decrypts to 1 iff x0+x1 >= 2  \n",
    "x0_sh = x0.fix_precision().share(alice, bob, crypto_provider=charlie).get()\n",
    "x1_sh = x1.fix_precision().share(alice, bob, crypto_provider=charlie).get()\n",
    "wrap_field = x0_sh * x1_sh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute exp of shares\n",
    "exp_x0, exp_x1 = [torch.exp(x0), torch.exp(x1)]\n",
    "alice._objects[exp_x0.id_at_location], bob._objects[exp_x1.id_at_location]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Share the exp of shares\n",
    "exp_x0_sh = exp_x0.fix_precision().share(alice, bob, crypto_provider=charlie).get()\n",
    "exp_x1_sh = exp_x1.fix_precision().share(alice, bob, crypto_provider=charlie).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply exp(x0 + x1) =  exp(x0) *  exp(x1) formula + a wrapping correction if needed\n",
    "one = torch.tensor([1.]).fix_precision()\n",
    "inv_exp_field_size = torch.exp(-torch.tensor([2.])).fix_precision()\n",
    "exp_sh = exp_x0_sh * exp_x1_sh * (wrap_field * (inv_exp_field_size - one) + one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and get 1.0\n",
    "exp_sh.get().float_prec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = torch.tensor([[3, 4]])\n",
    "y = torch.tensor([[3, 4]])\n",
    "x_sh = x.share(alice, bob, crypto_provider=charlie)\n",
    "y_sh = x.share(alice, bob, crypto_provider=charlie)\n",
    "\n",
    "result = x_sh * y_sh\n",
    "assert torch.equal(result.get(), x * y) \n",
    "\n",
    "alice.close()\n",
    "time.sleep(0.1)\n",
    "alice.remove_worker_from_local_worker_registry()\n",
    "\n",
    "bob.close()\n",
    "time.sleep(0.1)\n",
    "bob.remove_worker_from_local_worker_registry()\n",
    "\n",
    "charlie.close()\n",
    "time.sleep(0.1)\n",
    "charlie.remove_worker_from_local_worker_registry()\n",
    "server.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plaintext reference\n",
    "\n",
    "x = torch.tensor([[1.0, 2], [1.0, 2]])\n",
    "target = torch.tensor([[1.0], [1.0]])\n",
    "model = nn.Linear(2, 1)\n",
    "model.weight = nn.Parameter(torch.tensor([[-1.0, 2]]))\n",
    "model.bias = nn.Parameter(torch.tensor([-1.0]))\n",
    "\n",
    "output = model(x)\n",
    "loss = ((output - target) ** 2).sum()\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "expected_weight_grad = model.weight.grad\n",
    "expected_bias_grad = model.bias.grad\n",
    "\n",
    "# Classic share with requires_grad\n",
    "\n",
    "x = torch.tensor([[1.0, 2], [1.0, 2]]).fix_prec().share(bob, alice, crypto_provider=james, requires_grad=True)\n",
    "target = torch.tensor([[1.0], [1.0]]).fix_prec().share(bob, alice, crypto_provider=james, requires_grad=True)\n",
    "model = nn.Linear(2, 1)\n",
    "model.weight = nn.Parameter(torch.tensor([[-1.0, 2]]))\n",
    "model.bias = nn.Parameter(torch.tensor([-1.0]))\n",
    "model.fix_precision().share(bob, alice, crypto_provider=james, requires_grad=True)\n",
    "\n",
    "\n",
    "output = model(x)\n",
    "loss = ((output - target) ** 2).sum()\n",
    "loss.backward()\n",
    "\n",
    "weight_grad = model.weight.grad.get().float_precision()\n",
    "bias_grad = model.bias.grad.get().float_precision()\n",
    "\n",
    "assert (expected_weight_grad == weight_grad).all()\n",
    "assert (expected_bias_grad == bias_grad).all()\n",
    "\n",
    "# Remote (data+model) fix_prec+share with requires_grad\n",
    "\n",
    "x = torch.tensor([[1.0, 2], [1.0, 2]]).send(charlie).fix_prec().share(bob, alice, crypto_provider=james, requires_grad=True).get()\n",
    "target = torch.tensor([[1.0], [1.0]]).send(charlie).fix_prec().share(bob, alice, crypto_provider=james, requires_grad=True).get()\n",
    "model = nn.Linear(2, 1)\n",
    "model.weight = nn.Parameter(torch.tensor([[-1.0, 2]]))\n",
    "model.bias = nn.Parameter(torch.tensor([-1.0]))\n",
    "model.send(charlie).fix_precision().share(bob, alice, crypto_provider=james, requires_grad=True).get()\n",
    "\n",
    "\n",
    "output = model(x)\n",
    "loss = ((output - target) ** 2).sum()\n",
    "loss.backward()\n",
    "\n",
    "weight_grad = model.weight.grad.get().float_precision()\n",
    "bias_grad = model.bias.grad.get().float_precision()\n",
    "\n",
    "assert (expected_weight_grad == weight_grad).all()\n",
    "assert (expected_bias_grad == bias_grad).all()\n",
    "\n",
    "# Local fix_prec & remote data share with requires_grad\n",
    "\n",
    "x = torch.tensor([[1.0, 2], [1.0, 2]]).fix_prec().send(charlie).share(bob, alice, crypto_provider=james, requires_grad=True).get()\n",
    "target = torch.tensor([[1.0], [1.0]]).fix_prec().send(charlie).share(bob, alice, crypto_provider=james, requires_grad=True).get()\n",
    "model = nn.Linear(2, 1)\n",
    "model.weight = nn.Parameter(torch.tensor([[-1.0, 2]]))\n",
    "model.bias = nn.Parameter(torch.tensor([-1.0]))\n",
    "model.fix_precision().send(charlie).share(bob, alice, crypto_provider=james, requires_grad=True).get()\n",
    "\n",
    "\n",
    "output = model(x)\n",
    "loss = ((output - target) ** 2).sum()\n",
    "loss.backward()\n",
    "\n",
    "weight_grad = model.weight.grad.get().float_precision()\n",
    "bias_grad = model.bias.grad.get().float_precision()\n",
    "\n",
    "assert (expected_weight_grad == weight_grad).all()\n",
    "assert (expected_bias_grad == bias_grad).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1.0, 2], [1.0, 2]]).fix_prec().share(bob, alice, crypto_provider=james, requires_grad=True)\n",
    "target = torch.tensor([[1.0], [1.0]]).fix_prec().share(bob, alice, crypto_provider=james, requires_grad=True)\n",
    "model = nn.Linear(2, 1)\n",
    "model.weight = nn.Parameter(torch.tensor([[-1.0, 2]]))\n",
    "model.bias = nn.Parameter(torch.tensor([-1.0]))\n",
    "model.fix_precision().share(bob, alice, crypto_provider=james, requires_grad=True)\n",
    "\n",
    "\n",
    "output = model(x)\n",
    "loss = ((output - target) ** 2).sum()\n",
    "loss.backward()\n",
    "\n",
    "weight_grad = model.weight.grad.get().float_precision()\n",
    "bias_grad = model.bias.grad.get().float_precision()\n",
    "\n",
    "x = torch.tensor([[1.0, 2], [1.0, 2]])\n",
    "target = torch.tensor([[1.0], [1.0]])\n",
    "model = nn.Linear(2, 1)\n",
    "model.weight = nn.Parameter(torch.tensor([[-1.0, 2]]))\n",
    "model.bias = nn.Parameter(torch.tensor([-1.0]))\n",
    "\n",
    "output = model(x)\n",
    "loss = ((output - target) ** 2).sum()\n",
    "\n",
    "loss.backward()\n",
    "assert (model.weight.grad == weight_grad).all()\n",
    "assert (model.bias.grad == bias_grad).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_one = True\n",
    "a = (\n",
    "    torch.tensor([[3.0, 2], [-1, 2]], requires_grad=True)\n",
    "        .fix_prec()\n",
    "        .share(alice, bob, crypto_provider=james)\n",
    ")\n",
    "b = 2\n",
    "\n",
    "a = sy.AutogradTensor().on(a)\n",
    "\n",
    "a_torch = torch.tensor([[3.0, 2], [-1, 2]], requires_grad=True)\n",
    "b_torch = 2\n",
    "\n",
    "c = a / b\n",
    "c_torch = a_torch / b_torch\n",
    "\n",
    "ones = torch.ones(c.shape).fix_prec().share(alice, bob, crypto_provider=james)\n",
    "ones = sy.AutogradTensor().on(ones)\n",
    "c.backward(ones if backward_one else None)\n",
    "c_torch.backward(torch.ones(c_torch.shape))\n",
    "\n",
    "print(c.get().child.float_prec())\n",
    "print(a.grad.get().float_prec())\n",
    "print(a_torch.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob._objects\n",
    "(x_sh + x_sh).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([1, 2, 3, 4.0])\n",
    "ptr = t.send(james)\n",
    "\n",
    "x = ptr.fix_prec().share(bob, alice)\n",
    "\n",
    "y = x + x\n",
    "\n",
    "y = y.get().get().float_prec()\n",
    "assert (y == (t + t)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sh + x_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "\n",
    "import syft as sy\n",
    "hook = sy.TorchHook(torch)\n",
    "worker = sy.VirtualWorker(hook, id=\"alice\")\n",
    "\n",
    "class MyFunction(torch.autograd.Function):\n",
    "    def forward(self, x):\n",
    "        print(\"Custom forward called\")\n",
    "        return x\n",
    "    \n",
    "    def backward(self, grad_out):\n",
    "        grad_input = grad_out.clone()\n",
    "        print('Custom backward called!')\n",
    "        return grad_input\n",
    "\n",
    "\n",
    "x = torch.tensor([1.5], requires_grad=True)\n",
    "x = x.send(worker, local_autograd=True)\n",
    "\n",
    "y = MyFunction(x)\n",
    "print(y)\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import syft as sy\n",
    "hook = sy.TorchHook(torch)\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
    "james = sy.VirtualWorker(hook, id=\"james\")\n",
    "import sys\n",
    "\n",
    "alice = sy.VirtualWorker(hook, id=\"worker\")\n",
    "x = torch.tensor([1.])\n",
    "x_ptr = x.send(alice)\n",
    "x_fp = x_ptr.fix_prec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import syft as sy\n",
    "hook = sy.TorchHook(torch)\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
    "james = sy.VirtualWorker(hook, id=\"james\")\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "jon = james"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "\n",
    "import syft as sy\n",
    "hook = sy.TorchHook(torch)\n",
    "worker = sy.VirtualWorker(hook, id=\"alice\")\n",
    "\n",
    "class MyFunction(torch.autograd.Function):\n",
    "    def forward(self, x):\n",
    "        print(\"Custom forward called\")\n",
    "        return x\n",
    "    \n",
    "    def backward(self, grad_out):\n",
    "        grad_input = grad_out.clone()\n",
    "        print('Custom backward called!')\n",
    "        return grad_input\n",
    "\n",
    "\n",
    "x = torch.tensor([1.5], requires_grad=True)\n",
    "x = x.send(worker, local_autograd=True)\n",
    "\n",
    "y = MyFunction(x)\n",
    "print(y)\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wks = [ sy.VirtualWorker(hook, id=\"w#%d\" % i) for i in range(2) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wks = [alice, bob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.zeros(3,3)\n",
    "t = t.fix_prec().share(*wks, crypto_provider=james)\n",
    "t = t * 2\n",
    "t = t.get()\n",
    "t.float_prec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.tensor([1., 2., 3.]).fix_precision().send(alice)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.share(alice, bob, crypto_provider=jon)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ptr = th.tensor([1., 2., 3.]).fix_precision()#.send(jon)\n",
    "y_ptr = th.tensor([4., 5., 6.]).fix_precision()#.send(jon)\n",
    "\n",
    "x_shared = x_ptr.share(alice, bob, crypto_provider=jon)#.get()\n",
    "y_shared = y_ptr.share(alice, bob, crypto_provider=jon)#.get()\n",
    "\n",
    "print(x_shared)\n",
    "print(y_shared)\n",
    "secure_sum = x_shared + y_shared\n",
    "print(secure_sum)\n",
    "# (Wrapper)>FixedPrecisionTensor>[AdditiveSharingTensor]\n",
    "# \t-> (Wrapper)>[PointerTensor | me:92050228605 -> alice:43660865053]\n",
    "# \t-> (Wrapper)>[PointerTensor | me:15127770581 -> bob:67436046413]\n",
    "# \t*crypto provider: jon*\n",
    "\n",
    "secure_sum_squared = secure_sum * secure_sum\n",
    "print(secure_sum_squared)\n",
    "# (Wrapper)>FixedPrecisionTensor>None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ptr = th.tensor([1., 2., 3.]).fix_precision()\n",
    "y_ptr = th.tensor([4., 5., 6.]).fix_precision()\n",
    "\n",
    "x_shared = x_ptr.share(alice, bob, crypto_provider=jon)#.get()\n",
    "y_shared = y_ptr.share(alice, bob, crypto_provider=jon)#.get()\n",
    "\n",
    "secure_sum = x_shared + y_shared\n",
    "print(secure_sum)\n",
    "\n",
    "secure_sum_squared = secure_sum * secure_sum\n",
    "print(secure_sum_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 100\n",
    "base = 2\n",
    "prec = 3\n",
    "C = 10 #base ** prec\n",
    "print(q, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trunc(x1, x2):\n",
    "    return x1/C, q - (q - x2)/C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trunc(70, 70) # 40 -> 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _trunc(x1, x2):\n",
    "    if x1 > q/2:\n",
    "        x1 = (x1 - q)\n",
    "    if x2 > q/2:\n",
    "        x2 = (x2 - q)\n",
    "    x1 /= C\n",
    "    x2 /= C\n",
    "    return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_trunc(70, 70) # 40 -> 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc(x):\n",
    "    return np.round(x * C) % q\n",
    "\n",
    "def dec(x):\n",
    "    if x > q/2:\n",
    "        x = (x - q)\n",
    "    # Convert to float\n",
    "    return x / C\n",
    "\n",
    "def add(x, y):\n",
    "    z = x + y\n",
    "    return z % q\n",
    "\n",
    "def mul(x, y):\n",
    "    z = (x * y) % q\n",
    "    r = dec(z)\n",
    "    print(r)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q/(C*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = -1, 4\n",
    "_a = enc(a)\n",
    "_b = enc(b)\n",
    "print(dec(add(_a, _b)))\n",
    "print(dec(mul(_a, _b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1025 - 8 * 8 *4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = -2\n",
    "b = -3\n",
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mul(x, y):\n",
    "    return ((x * y) % q)/C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul(enc(a), enc(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dec(x):\n",
    "    if x > q/2:\n",
    "        x = (x - q)\n",
    "    # Convert to float\n",
    "    return x / C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec(1017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec(mul(enc(a), enc(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2\n",
    "b = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec(mul(enc(a), enc(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = -2\n",
    "b = 1\n",
    "enc(a), enc(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(enc(a) * enc(b)) % q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec(897) / C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul(enc(a), enc(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc(-3*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc(x):\n",
    "    return (x * C) % field\n",
    "def dec(x):\n",
    "    ## wrap in [0, q]\n",
    "    #x = x % q\n",
    "    # wrap in [-q/2, q/2]\n",
    "    if x > q/(2):\n",
    "        x = (x - q)\n",
    "    # Convert to float\n",
    "    return x / C\n",
    "def add(x, y):\n",
    "    return (x + y) % q\n",
    "def mul(x, y):\n",
    "    return np.round((x * y) / C) % q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = -1, -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul(enc(a), enc(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec(mul(enc(a), enc(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.])\n",
    "p = x.send(bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "l = []\n",
    "x = torch.tensor([1.])\n",
    "p = x.send(bob)\n",
    "for i in range(10000):\n",
    "    if hasattr(p, 'child'):\n",
    "        l.append(p.child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "l = []\n",
    "x = torch.tensor([1.])\n",
    "p = x.send(bob)\n",
    "for i in range(10000):\n",
    "    try:\n",
    "        l.append(p.child)\n",
    "    except KeyError:\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "l = []\n",
    "for i in range(10000):\n",
    "    x = torch.tensor([1.])\n",
    "    p = x.send(bob)\n",
    "    if hasattr(p, 'child'):\n",
    "        l.append(p.child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "l = []\n",
    "for i in range(10000):\n",
    "    x = torch.tensor([1.])\n",
    "    p = x.send(bob)\n",
    "    try:\n",
    "        l.append(p.child)\n",
    "    except KeyError:\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec(mul(a_fp, b_fp)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a * (b * C + q) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a * b * C + a * q  ,   a * b * C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec((a * (b * C + q)) % q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul(x_fp, y_fp) % (field * base ** prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec(mul(x_fp, y_fp)), x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.25 * (6.625 - field / base ** prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.tensor([1.])\n",
    "x_fp = x.fix_precision()\n",
    "\n",
    "r_fp = x_fp / 5\n",
    "r = r_fp.float_precision()\n",
    "print(r)\n",
    "assert r_fp.float_precision() == x / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.tensor([1.])\n",
    "x_fp = x.fix_precision()\n",
    "\n",
    "r_fp = x_fp + 10\n",
    "r = r_fp.float_precision()\n",
    "print(r)\n",
    "assert r == x + 10\n",
    "\n",
    "r_fp = x_fp - 7\n",
    "r = r_fp.float_precision()\n",
    "print(r)\n",
    "assert r == x - 7\n",
    "\n",
    "r_fp = x_fp * 2\n",
    "assert r_fp.float_precision() == x * 2\n",
    "\n",
    "r_fp = x_fp / 5\n",
    "assert r_fp.float_precision() == x / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.tensor([2.])\n",
    "x_sh = x.fix_precision().share(alice, bob, crypto_provider=james)\n",
    "\n",
    "r_sh = x_sh + 10\n",
    "assert r_sh.get().float_prec() == x + 10\n",
    "\n",
    "r_sh = x_sh - 7\n",
    "assert r_sh.get().float_prec() == x - 7\n",
    "\n",
    "r_sh = x_sh * 2\n",
    "assert r_sh.get().float_prec() == x * 2\n",
    "\n",
    "r_sh = x_sh / 2\n",
    "assert r_sh.get().float_prec() == x / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.tensor([1.])\n",
    "y = th.tensor([2.])\n",
    "z = torch.mul(x, y)\n",
    "z.backward()\n",
    "z.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.tensor([1])\n",
    "x = x.share(alice, bob, crypto_provider=james).child\n",
    "y = th.tensor([2])\n",
    "y = y.share(alice, bob, crypto_provider=james).child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.mul(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z\n",
    "z.virtual_get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.tensor([1, 2])\n",
    "x.wrap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.tensor([1, 6])\n",
    "xsh = x.share(alice, bob, crypto_provider=james).child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = []\n",
    "kwargs = {'dim':0}\n",
    "self = xsh\n",
    "\n",
    "summ = self.sum(*args, **kwargs)\n",
    "\n",
    " # We need to know how many input values are used for each\n",
    "# output value to divide\n",
    "dims_to_reduce = args if args else range(self.dim())\n",
    "print(dims_to_reduce)\n",
    "\n",
    "div = 1\n",
    "for i, s in enumerate(self.shape):\n",
    "    if i in dims_to_reduce:\n",
    "        div *= s\n",
    "\n",
    "z = summ // div\n",
    "z.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "other_shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        self.fc3 = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = Net()\n",
    "\n",
    "# The data itself doesn't matter as long as the shape is right\n",
    "mock_data = torch.zeros(1, 2)\n",
    "\n",
    "# Create a jit version of the model\n",
    "traced_model = torch.jit.trace(model, mock_data)\n",
    "\n",
    "type(traced_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(traced_model, torch.jit.ScriptModule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def loss_fn(real, pred):\n",
    "    return ((real.float() - pred.float()) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(loss_fn, torch.jit.ScriptModule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1, 2, 3]\n",
    "l.drop(4)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor([-1., -2, 3, 4])\n",
    "x = x.fix_precision()\n",
    "print(x)\n",
    "x_priv = x.share(alice, bob, crypto_provider=james)\n",
    "print(x)\n",
    "x = torch.max(x)\n",
    "x.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([1., 2, 3, 4]).send(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([1., 2, 3, 4]).fix_precision().share(alice, bob, crypto_provider=james)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.add(t, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.child.child.child.torch.nn.__module__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.child.child.child.torch.stack.__module__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack([t, t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([1., 2, 3, 4]).fix_precision().share(alice, bob, crypto_provider=james)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = torch.tensor([0.5]).fix_precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.child.child.child, lr.child.child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t * lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.child.child.child * lr.child.child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_copy=[0]*2;\n",
    "for epoch in range(1, 2):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(federated_train_loader): # <-- now it is a distributed dataset\n",
    "        if batch_idx==0:\n",
    "            bobmodel=model.copy().send(data.location) # <-- NEW: send the model to the rig\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = bobmodel(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            loss = loss.get() # <-- NEW: get the loss back\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * args.batch_size, len(federated_train_loader) * args.batch_size,\n",
    "                100. * batch_idx / len(federated_train_loader), loss.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([1, 2, 3, 4]).send(bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.shape == torch.Size([4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([1, 2, 3, 4])\n",
    "x = t.share(bob, alice, crypto_provider=james)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptr_to_sh = x.send(bob)\n",
    "pointer = ptr_to_sh.remote_get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.tensor([1, 2, 3, 4]).send(bob)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.copy().move(alice).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([1, 2, 3, 4])\n",
    "x = t.share(bob, alice, crypto_provider=james)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alice._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = x.child.reconstruct()\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([1, 2, 3, 4])\n",
    "x = t.share(bob, alice, crypto_provider=james)\n",
    "print(x)\n",
    "y = (x * x)\n",
    "\n",
    "#z = y.get()\n",
    "\n",
    "#assert (y == (t * t)).all() 72265325022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3, 4, 5]).send(bob)\n",
    "x.move(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 3)\n",
    "        self.fc2 = nn.Linear(3, 2)\n",
    "\n",
    "    @sy.method2plan\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=0)\n",
    "    \n",
    "    def your(self, x):\n",
    "        return self.forward(self, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class MyModule(torch.jit.ScriptModule):\n",
    "    def __init__(self, N, M):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.weight = torch.nn.Parameter(torch.rand(N, M))\n",
    "\n",
    "    @torch.jit.script_method\n",
    "    def forward(self, input):\n",
    "        if bool(input.sum() > 0):\n",
    "            output = self.weight.mv(input)\n",
    "        else:\n",
    "            output = self.weight + input\n",
    "        return output\n",
    "\n",
    "my_script_module = MyModule(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_script_module.save(\"playground_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_script_module.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import syft as sy\n",
    "hook = sy.TorchHook(torch)\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
    "james = sy.VirtualWorker(hook, id=\"james\")\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = torch.tensor([3, 2., 0], requires_grad=True)\n",
    "b = torch.tensor([1., 2, 3], requires_grad=True)\n",
    "\n",
    "a = a.fix_precision().share(alice, bob, local_autograd=True, crypto_provider=james)\n",
    "b = b.fix_precision().share(alice, bob, local_autograd=True, crypto_provider=james)\n",
    "\n",
    "c = a + b\n",
    "\n",
    "#c.child.backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([3, 2., 0], requires_grad=True)\n",
    "a = a.send(alice, local_autograd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.child.grad_fn #.grad_fn = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = torch.tensor([3, 2.0, 0], requires_grad=True)\n",
    "b = torch.tensor([1, 2.0, 3], requires_grad=True)\n",
    "\n",
    "a = a.send(alice, local_autograd=True)\n",
    "b = b.send(alice, local_autograd=True)\n",
    "\n",
    "a_torch = torch.tensor([3, 2.0, 0], requires_grad=True)\n",
    "b_torch = torch.tensor([1, 2.0, 3], requires_grad=True)\n",
    "\n",
    "c = a + b\n",
    "c_torch = a_torch + b_torch\n",
    "\n",
    "c.backward(torch.ones(c.shape).send(alice))\n",
    "c_torch.backward(torch.ones(c_torch.shape))\n",
    "\n",
    "assert (a.grad.get() == a_torch.grad).all()\n",
    "assert (b.grad.get() == b_torch.grad).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = {'bob': bob, 'alice': alice}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tensor\n",
    "x = torch.Tensor([1, 2])\n",
    "\n",
    "# send tensor to bob and then pointer to alice\n",
    "x_ptr = x.send(workers[\"bob\"])\n",
    "x_ptr_ptr = x_ptr.send(workers[\"alice\"])\n",
    "\n",
    "# ensure bob has tensor\n",
    "assert x.id in workers[\"bob\"]._objects\n",
    "\n",
    "# delete pointer to pointer to tensor, which should automatically\n",
    "# garbage collect the remote object on Bob's machine\n",
    "\n",
    "print(sys.getrefcount(workers[\"bob\"]._objects[x.id]))\n",
    "del x_ptr_ptr\n",
    "\n",
    "# ensure bob's object was garbage collected\n",
    "assert x.id not in workers[\"bob\"]._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tensor\n",
    "x = torch.Tensor([1, 2])\n",
    "\n",
    "# send tensor to bob and then pointer to alice\n",
    "x_ptr = x.send(bob)\n",
    "\n",
    "print('<<')\n",
    "print(sys.getrefcount(bob._objects[x_ptr.id_at_location]))\n",
    "print('>>')\n",
    "x_ptr_ptr = x_ptr.send(alice)\n",
    "\n",
    "# ensure bob has tensor\n",
    "assert x.id in bob._objects\n",
    "\n",
    "# delete pointer to pointer to tensor, which should automatically\n",
    "# garbage collect the remote object on Bob's machine\n",
    "\n",
    "print(sys.getrefcount(alice._objects[x_ptr_ptr.id_at_location]))\n",
    "print(sys.getrefcount(bob._objects[x.id]))\n",
    "del x_ptr_ptr\n",
    "\n",
    "# ensure bob's object was garbage collected\n",
    "assert x.id not in bob._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(2, 1)\n",
    "model.weight = nn.Parameter(model.weight * 100)\n",
    "model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(2, 1)\n",
    "model.weight = nn.Parameter(torch.tensor([[-1.0, 2]]))\n",
    "#model.bias = nn.Parameter(torch.tensor([[1.0]]))\n",
    "print(model.weight)\n",
    "model.fix_precision().share(bob, alice, crypto_provider=james)\n",
    "model.weight.child.child.child.virtual_get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = nn.Parameter(torch.tensor([[-1.0, 2]]))\n",
    "o = p.sum()\n",
    "o.backward()\n",
    "p.grad -= p.grad\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(2, 1)\n",
    "model.weight = nn.Parameter(torch.tensor([[-1.0, 2]]))\n",
    "#for p in model.parameters():\n",
    "#    p.fix_precision_().share_(bob, alice, crypto_provider=james)\n",
    "model.fix_precision().share(bob, alice, crypto_provider=james)\n",
    "\n",
    "print(model.weight.child.child.child.virtual_get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = nn.Parameter(torch.tensor([[-1.0, 2]]))\n",
    "p.fix_precision_().share_(bob, alice, crypto_provider=james)\n",
    "print(p.child.child.child.virtual_get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.weight.child.child.child.virtual_get(), model.bias.child.child.child.virtual_get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([[1.0, 2]])\n",
    "x = t.fix_prec().share(bob, alice, crypto_provider=james)\n",
    "model = nn.Linear(2, 1)\n",
    "model.weight = nn.Parameter(torch.tensor([[-1.0, 2]]))\n",
    "model.bias = nn.Parameter(torch.tensor([[-1.0]]))\n",
    "model.fix_precision().share(bob, alice, crypto_provider=james)\n",
    "\n",
    "y = model(x)\n",
    "\n",
    "back = y.get().float_prec()\n",
    "print(back)\n",
    "assert back == torch.tensor([[2.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([[1.0, 2]])\n",
    "x = t\n",
    "model = nn.Linear(2, 1)\n",
    "model.weight = nn.Parameter(torch.tensor([[-1.0, 2]]))\n",
    "model.bias = nn.Parameter(torch.tensor([[-1.0]]))\n",
    "\n",
    "y = model(x)\n",
    "\n",
    "back = y\n",
    "print(back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tensor = torch.tensor([1, 2, 3, 4.0])\n",
    "ptr = tensor.send(bob)\n",
    "r_ptr = torch.split(ptr, 2)\n",
    "assert (r_ptr[0].get() == torch.tensor([1, 2.0])).all()\n",
    "\n",
    "tensor = torch.tensor([1, 2, 3, 4.0])\n",
    "ptr = tensor.send(bob)\n",
    "max_value, argmax_idx = torch.max(ptr, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Pysyft)",
   "language": "python",
   "name": "pysyft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
